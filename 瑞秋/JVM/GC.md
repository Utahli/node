# 深入理解JVM(2)——GC算法与内存分配策略

## 

Posted by Crow on August 10, 2017

说起**垃圾收集（Garbage Collection, GC）**，想必大家都不陌生，它是JVM实现里非常重要的一环，JVM成熟的内存动态分配与回收技术使Java（当然还有其他运行在JVM上的语言，如Scala等）程序员在提升开发效率上获得了惊人的便利。理解GC，对于理解JVM和Java语言有着非常重要的作用。并且当我们需要排查各种内存溢出、内存泄漏问题时，当垃圾收集称为系统达到更高并发量的瓶颈时，只有深入理解GC和内存分配，才能对这些“自动化”的技术实施必要的监控和调节。

在Java的运行时数据区中，程序计数器、虚拟机栈、本地方法栈三个区域都是线程私有的，随线程而生，随线程而灭，在方法结束或线程结束时，内存自然就跟着回收了，不需要过多考虑回收的问题。而**Java堆**和**方法区**则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间才能知道会创建哪些对象，这部分内存的分配和回收都是动态的，垃圾回收器关注的是这部分内存，后续讨论的“内存”分配回收也是指这一块，尤其需要注意。

GC主要回答了以下三个问题：

- 哪些内存需要回收？
- 什么时候回收？
- 如何回收？

这三个问题的具体解决方案，也就是本文接下来要讲解的内容。

# 对象存活判定算法

在堆里存放着Java世界中几乎所有的对象实例，垃圾收集器在对堆进行回收前，首要的就是确定这些对象中哪些还“存活”着，哪些已经“死去”（即不可能再被任何途径使用的对象）。

#### 引用计数算法

引用计数算法是在JVM中被摒弃的一种对象存活判定算法，不过它也有一些知名的应用场景（如Python、FlashPlayer），因此在这里也简单介绍一下。

用引用计数器判断对象是否存活的过程是这样的==：**给对象中添加一个引用计数器，每当有一个地方引用它时，计数器加1；当引用失效时，计数器减1；任何时刻计数器为0的对象就是不可能再被使用的。**==

引用计数算法的实现简单，判定效率也很高，大部分情况下是一个不错的算法。它没有被JVM采用的原因是==**它很难解决对象之间循环引用的问题**。==例如以下例子：

```
/** * testGC()方法执行后，objA和objB会不会被GC呢？ */
public class ReferenceCountingGC {

    public Object instance = null;

    private static final int _1MB = 1024 * 1024;

    /** * 这个成员属性的唯一意义就是占点内存，以便在能在GC日志中看清楚是否有回收过 */
    private byte[] bigSize = new byte[2 * _1MB];

    public static void testGC() {
        ReferenceCountingGC objA = new ReferenceCountingGC();
        ReferenceCountingGC objB = new ReferenceCountingGC();
        objA.instance = objB;
        objB.instance = objA;

        objA = null;
        objB = null;

        // 假设在这行发生GC，objA和objB是否能被回收？
        System.gc();
    }
}
```

在上面这段代码中，对象objA 和对象objB都有字段instance，赋值令`objA.instance = objB;`、`objB.instance = objA;`，除此之外，这两个对象再无引用。如果JVM采用引用计数算法来管理内存，==**这两个对象不可能再被访问，但是他们互相引用着对方，导致它们引用计数不为0，所以引用计数器无法通知GC收集器回收它们**。==

而事实上执行这段代码，objA和objB是可以被回收的，下面一节将介绍JVM实际使用的存活判定算法。

#### 可达性分析算法

在主流商用程序语言的实现中，都是通过**可达性分析（tracing GC）**来判定对象是否存活的。此算法的基本思路是：通过一系列的称为**“GC Roots”**的对象作为起点，从这些节点向下搜索，搜索所走过的路径称为**引用链（Reference Chain）**，当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是GC Roots 到这个对象不可达）时，则证明此对象时不可用的。用下图来加以说明：

![img](https://pic.yupoo.com/crowhawk/5d0246eb/0635cbe8.png))

上图中，对象object 5、object 6、object 7虽然互有关联，但是它们到GC Roots是不可达的，所以它们将会被判定为是可回收的对象。

可以看到，GC Roots在对象图之外，是特别定义的**“起点”**，不可能被对象图内的对象所引用。

==准确地说，**GC Roots其实不是一组对象，而通常是一组特别管理的指向引用类型对象的指针**，这些指针是tracing GC的trace的起点。它们不是对象图里的对象，对象也不可能引用到这些“外部”的指针，这也是tracing GC算法不会出现循环引用问题的基本保证。因此也容易得出，**只有引用类型的变量才被认为是Roots，值类型的变量永远不被认为是Roots**。只有深刻理解引用类型和值类型的内存分配和管理的不同，才能知道为什么root只能是引用类型。==

==在Java中，可作为GC Roots的对象包括以下几种：==

- ==**虚拟机栈（栈帧中的局部变量表，Local Variable Table）**中引用的对象。==
- ==**方法区中类静态属性**引用的对象。==
- ==**方法区中常量**引用的对象。==
- ==**本地方法栈中JNI（即一般说的Native方法）**引用的对象。==

看到这里你可能要问，选择这些对象的依据是什么呢？

可以概括得出，可作为GC Roots的节点主要在**全局性的引用**与**执行上下文**中。要明确的是，tracing gc必须**以当前存活的对象集为Roots**，因此必须选取确定存活的引用类型对象。GC管理的区域是Java堆，**虚拟机栈**、**方法区**和**本地方法栈**不被GC所管理，因此选用这些区域内引用的对象作为GC Roots，是**不会被GC所回收**的。其中虚拟机栈和本地方法栈都是线程私有的内存区域，只要线程没有终止，就能确保它们中引用的对象的存活。而方法区中类静态属性引用的对象是显然存活的。常量引用的对象在当前可能存活，因此，也可能是GC roots的一部分。

#### ==两次标记与 finalize()方法==

即使在可达性分析算法中不可达的对象，也不是一定会死亡的，它们暂时都处于**“缓刑”**阶段，要真正宣告一个对象“死亡”，至少要经历两次标记过程：

如果对象在进行可达性分析后发现没有与 GC Roots相连接的引用链，那它将会被**第一次标记**并且进行一次筛选，筛选的条件是**此对象是否有必要执行finaliza()方法**。当对象没有覆盖`finaliza()`方法，或者`finaliza()`方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。

如果这个对象被判定为有必要执行`finaliza()`方法，那么此对象将会放置在一个叫做 F-Queue 的队列中，并在稍后由一个虚拟机自动建立的、低优先级的Finalizer线程去执行它。这里所谓的“执行”是指虚拟机会触发此方法，但并不承诺会等待它运行结束，原因是：如果一个对象在`finaliza()`方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能导致F-Queue 队列中的其它对象永久处于等待，甚至导致整个内存回收系统崩溃。

`finaliza()`方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue 队列中的对象进行**第二次小规模的标记**。如果对象想在`finaliza()`方法中成功拯救自己，**只要重新与引用链上的任何一个对象建立关联即可，例如把自己（this关键字）赋值给某个类变量或者对象的成员变量，这样在第二次标记时它将被移出“即将回收”的集合**；如果对象这时候还没有逃脱，基本上它就真的被回收了。

值得注意的是，如果代码中有两段一模一样的代码段，执行结果却是一次逃脱成功，一次失败。这是因为任何一个对象的`finalize()`方法都只会被系统调用一次，如果对象面临下一次回收，它的`finalize()`方法不会再被执行，因此第二次逃脱行动失败。

需要说明的是，使用`finalize()`方法来“拯救”对象是不值得提倡的，因为它不是C/C++中的析构函数，而是Java刚诞生时为了使C/C++程序员更容易接受它所做的一个妥协。**它的运行代价高昂，不确定性大，无法保证各个对象的调用顺序。**`finalize() `能做的工作，使用`try-finally`或者其它方法都更适合、及时，所以笔者建议大家可以忘掉此方法存在。

# 鲜为人知的二次标记

  上一章我们讲到了[标记](http://blog.csdn.net/sunhuaqiang1/article/details/54457075)，但是不是被标记了就肯定会被回收呢？不知道小伙伴们记不记得Object类有一个finalize()方法，所有类都继承了Object类，因此也默认实现了这个方法。 
  这个方法的用途就是：在该对象被回收之前，该对象的finalize()方法会被调用。这里的回收之前指的就是被标记之后，问题就出在这里，有没有一种情况就是原本一个对象开始不在上一章所讲的“关系网”（引用链）中，但是当开发者重写了finalize()后，并且将该对象重新加入到了“关系网”中，也就是说该对象对我们还有用，不应该被回收，但是已经被标记啦，怎么办呢？ 
  ==针对这个问题，虚拟机的做法是进行两次标记，即第一次标记不在“关系网”中的对象。第二次的话就要先判断该对象有没有实现finalize()方法了，如果没有实现就直接判断该对象可回收；如果实现了就会先放在一个队列中，并由虚拟机建立的一个低优先级的线程去执行它，随后就会进行第二次的小规模标记，在这次被标记的对象就会真正的被回收了。我们来看下面的代码：== 
![](D:\workspace\Github\node\瑞秋\JVM\assets\20170121165853848.jpg)
  大家觉得他会输出什么？最后的结果是： 
    我被调用啦 
    我还活着 
    我挂啦 
  有木有觉得很诧异，明明调用了两次同样的方法，但输出怎么不同呢？而且明明调用了两次gc()方法（这里确认是执行了gc）,那怎么只进入了一次finalize()方法？ 
  嘿嘿，其实面对同一个对象，他的finalize()方法只会被调用一次，因此第一次调用的时候会进行finalize()方法，并且成功的将该对象加入了“关系网”中，但当第二次回收的时候并不会进入，所以第二次不能将对象加入“关系网”中，导致被回收了。 
   图中有一行让程序睡眠一秒钟的代码，为的就是确保让低优先级的执行finalize()方法线程执行完成。那如果我们把他注释了会怎样呢？输出结果是： 
    我挂啦 
    我被调用啦 
    我挂啦 
  很奇怪吧，不过如果执行很多次的话，也会出现最开始那样的结果，但多数会是这个结果。因为我们已经说了，执行finalize()的是一个低优先级的线程，既然是一个新的线程，虽然优先级低了点，但也是和垃圾收集器并发执行的，所以垃圾收集器没必要等这个低优先级的线程执行完才继续执行。也就是说，finalize()方法不一定会在对象第一次标记后执行。用一句清晰易懂的话来说就是：虚拟机确实有调用方法的动作，但是不会确保在什么时候执行完成。因此也就出现了上面输出的结果，对象被回收之后，那个低优先级的线程才执行完。

 

#### 回收方法区

很多人认为方法区没有垃圾回收，Java虚拟机规范中确实说过不要求，而且在方法区中进行垃圾收集的“性价比”较低：在堆中，尤其是新生代，常规应用进行一次垃圾收集可以回收70%~95%的空间，而方法区的效率远低于此。在JDK 1.8中，JVM摒弃了永久代，用元空间来作为方法区的实现，下面介绍的将是元空间的垃圾回收。

====元空间的内存管理由**元空间虚拟机**来完成。先前，对于类的元数据我们需要不同的垃圾回收器进行处理，现在只需要执行元空间虚拟机的C++代码即可完成。**在元空间中，类和其元数据的生命周期**和**其对应的类加载器**是相同的。话句话说，**只要类加载器存活，其加载的类的元数据也是存活的**，因而不会被回收掉。====

====我们从行文到现在提到的元空间稍微有点不严谨。准确的来说，**每一个类加载器的存储区域都称作一个元空间，所有的元空间合在一起就是我们一直说的元空间。**当一个类加载器被垃圾回收器标记为不再存活，其对应的元空间会被回收。在元空间的回收过程中没有重定位和压缩等操作。但是元空间内的元数据会进行扫描来确定Java引用。====

# 垃圾收集算法

本节将介绍几种垃圾收集算法的思想及其发展过程，具体的实现将在稍后介绍。

#### 标记－清除（Mark-Sweep）算法

**标记－清除（Mark-Sweep）**算法是最基础的垃圾收集算法，后续的收集算法都是基于它的思路并对其不足进行改进而得到的。顾名思义，==算法分成“标记”、“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象，标记过程在前一节讲述对象标记判定时已经讲过了。==

标记－清除算法的不足主要有以下两点：

- ==**空间问题**，标记清除之后会产生大量不连续的**内存碎片**，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不触发另一次垃圾收集动作。==
- ==**效率问题**，因为内存碎片的存在，操作会变得更加费时，因为查找下一个可用空闲块已不再是一个简单操作。==

标记－清除算法的执行过程如下图所示：

![img](https://pic.yupoo.com/crowhawk/5a3494ae/efc6204a.png)

#### 复制（Copying）算法

为了解决标记-清除算法的效率问题，一种称为**“复制”（Copying）**的收集算法出现了，思想为：==它**将可用内存按容量分成大小相等的两块**，每次只使用其中的一块。**当这一块内存用完，就将还存活着的对象复制到另一块上面**，然后再把已使用过的内存空间一次清理掉。==

这样做使得**每次都是对整个半区进行内存回收**，内存分配时也就**不用考虑内存碎片**等复杂情况，只要**移动堆顶指针，按顺序分配内存**即可，实现简单，运行高效。==只是这种算法的代价是**将内存缩小为原来的一半**，代价可能过高了。==复制算法的执行过程如下图所示：

![img](https://pic.yupoo.com/crowhawk/62b8a3a8/f1cada8a.png)

**Minor GC与复制算法**

**现在的商业虚拟机都使用复制算法来回收新生代。**新生代的GC又叫**“Minor GC”**，IBM公司的专门研究表明：新生代中的对象98%是**“朝生夕死”**的，所以Minor GC非常频繁，一般回收速度也比较快，同时**“朝生夕死”**的特性也使得Minor GC使用复制算法时不需要按照1:1的比例来划分新生代内存空间。

**Minor GC过程**

==事实上，新生代将内存分为**一块较大的Eden空间**和**两块较小的Survivor空间（From Survivor和To Survivor）**，**每次Minor GC都使用Eden和From Survivor**，当回收时，**将Eden和From Survivor中还存活着的对象都一次性地复制到另外一块To Survivor空间上**，最后清理掉Eden和刚使用的Survivor空间。**一次Minor GC结束的时候**，**Eden**空间和**From Survivor**空间都是空的，而**To Survivor**空间里面存储着存活的对象。**在下次MinorGC的时候**，两个Survivor空间交换他们的标签，现在是空的**“From” Survivor**标记成为**“To”**，**“To” Survivor**标记为**“From”**。因此，在MinorGC结束的时候，Eden空间是空的，两个Survivor空间中的一个是空的，而另一个存储着存活的对象。==

HotSpot虚拟机默认的**Eden : Survivor**的比例是**8 : 1**，由于一共有两块Survivor，所以**每次新生代中可用内存空间为整个新生代容量的90%（80%＋10%）**，只有10%的容量会被“浪费”。

**分配担保**

==上文说的98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，**当Survivor空间不够用时**，需要依赖**老年代内存**进行**分配担保（Handle Promotion）**。==如果另外一块Survivor上没有足够空间存放上一次新生代收集下来的存活对象，这些对象将直接通过分配担保机制进入老年代。

##### 标记－整理（Mark-Compact）算法

复制算法在对象存活率较高时要进行较多的复制操作，效率将会变低。更关键的是：如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在**老年代一般不能直接选用复制算法**。

根据老年代的特点，**标记－整理（Mark-Compact）**算法被提出来，主要思想为：==此算法的标记过程与**标记－清除**算法一样，但后续步骤不是直接对可回收对象进行清理，而是**让所有存活的对象都向一端移动，然后直接清理掉边界以外的内存。**==具体示意图如下所示：

![img](https://pic.yupoo.com/crowhawk/d046244a/d3d3277f.png)

##### 分代收集（Generational Collection）算法

当前商业虚拟机的垃圾收集都采用**分代收集（Generational Collection）算法**，此算法相较于前几种没有什么新的特征，主要思想为：根据对象存活周期的不同将内存划分为几块，一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适合的收集算法：

- ==**新生代** 在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用**复制算法**，只需要付出少量存活对象的复制成本就可以完成收集。==
- ==**老年代** 在老年代中，因为对象存活率高、没有额外空间对它进行分配担保，就必须使用**“标记-清除”**或**“标记-整理”**算法来进行回收。==

# HotSpot的算法实现

前面两大节主要从理论上介绍了对象存活判定算法和垃圾收集算法，而在HotSpot虚拟机上实现这些算法时，必须对算法的执行效率有严格的考量，才能保证虚拟机高效运行。

#### 枚举根节点

从可达性分析中**从GC Roots节点找引用链**这个操作为例，可作为GC Roots的节点主要在**全局性的引用**（例如常量或类静态属性）与**执行上下文**（例如栈帧中的局部变量表）中，现在很多应用仅仅方法区就有数百兆，如果要逐个检查这里面的引用，那么必然会消耗很多时间。

**GC停顿（”Stop The World”）**

另外，==**可达性分析工作**必须在一个**能确保一致性的快照**中进行——这里**“一致性”**的意思是指**在整个分析期间整个执行系统看起来就像被冻结在某个时间点上**，不可以出现分析过程中对象引用关系还在不断变化的情况，这是保证分析结果准确性的基础。这点是导致GC进行时必须**停顿所有Java执行线程**（Sun将这件事情称为**“Stop The World”**）的其中一个重要原因，即使是在号称（几乎）不会发生停顿的CMS收集器中，枚举根节点时也是必须要停顿的。==

**准确式GC与OopMap**

由于目前的主流Java虚拟机使用的都是**准确式GC（即使用准确式内存管理，虚拟机可用知道内存中某个位置的数据具体是什么类型）**，所以当执行系统停顿下来后，并不需要一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放着对象引用。在HotSpot的实现中，是使用一组称为**OopMap**的数据结构来达到这个目的的，在类加载完成的时候，HotSpot就把**对象内什么偏移量上是什么类型的数据**计算出来，在JIT编译过程中，也会在特定的位置记录下**栈和寄存器中哪些位置是引用**。这样，GC在扫描时就可以直接得知这些信息了。

#### 安全点（Safepoint）——进行GC时程序停顿的位置

在OopMap的协助下，HotSpot可以快速且准确地完成GC Roots枚举，但一个很现实的问题随之而来：可能导致引用关系变化，或者说OopMap内容变化的指令非常多，**如果为每一条指令都生成对应的OopMap，那将会需要大量的额外空间，这样GC的空间成本将会变得很高。**

为此，HotSpot选择不为每条指令都生成OopMap，而是只在“特定的位置”记录这些信息，这些位置便被称为**安全点（Safepoint）**。也就是说，==**程序执行时并非在所有地方都能停顿下来开始GC，只有在到达安全点时才能暂停**。==Safepoint的选定既不能太少以致于让GC等待时间太长，也不能过于频繁以致于过分增大运行时的负荷。所以，安全点的选定基本上是以程序**“是否具有让程序长时间执行的特征”**为标准进行选定的——因为每条指令执行的时间都非常短暂，程序不太可能因为指令流长度太长这个原因而过长时间运行，“长时间执行”的最明显特征就是**指令序列复用**，例如**方法调用**、**循环跳转**、**异常跳转**等，所以具有这些功能的指令才会产生Safepoint。

==对于Sefepoint，另一个需要考虑的问题是如何**在GC发生时让所有线程（这里不包括执行JNI调用的线程）都“跑”到最近的安全点上再停顿下来**。这里有两种方案可供选择：==

- ==**抢先式中断（Preemptive Suspension）** 抢先式中断不需要线程的执行代码主动去配合，**在GC发生时，首先把所有线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，让它“跑”到安全点上==。**现在几乎没有虚拟机实现采用抢先式中断来暂停线程从而响应GC事件。
- ==**主动式中断（Voluntary Suspension）**： 主动式中断的思想是当GC需要中断线程的时候，不直接对线程操作，仅仅简单地**设置一个标志**，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起。**轮询标志的地方和安全点是重合的**，另外**再加上创建对象需要分配内存的地方**。==

#### 安全区域（Safe Region）

**Safepoint**机制保证了**程序执行时**，在不太长的时间内就会遇到可进入GC的Safepoint。但是，**程序“不执行”的时候（如线程处于Sleep状态或Blocked状态）**，这时线程无法响应JVM的中断请求，“走到”安全的地方去中断挂起，这时候就需要**安全区域（Safe Region）**来解决。

==安全区域是指**在一段代码片段之中，引用关系不会发生变化。在这个区域中的任意地方开始GC都是安全的。**==我们也可以把Safe Region看做是被扩展了的Safepoint。

==在线程执行到Safe Region中的代码时，首先**标识自己已经进入了Safe Region**，那样，当在这段时间里JVM要发起GC时，就不用管标识自己为Safe Region状态的线程了。**在线程要离开Safe Region时，它要检查系统是否已经完成了根节点枚举（或者是整个GC过程）**，如果完成了，那线程就继续执行，否则它就必须等待直到收到可以安全离开Safe Region的信号为止。==

# 内存分配策略

Java的自动内存管理最终可以归结为自动化地解决了两个问题：

- **给对象分配内存**
- **回收分配给对象的内存**

对==象的内存分配通常是在堆上分配（除此以外还有可能经过JIT编译后被拆散为标量类型并间接地栈上分配），对象主要分配在新生代的Eden区上，如果启动了本地线程分配缓冲，将按线程优先在TLAB上分配。==少数情况下也可能会直接分配在老年代中，分配的规则并不是固定的，实际取决于垃圾收集器的具体组合以及虚拟机中与内存相关的参数的设置。至于内存回收策略，在上文已经描述得很详尽了。

下面以使用Serial/Serial Old收集器（将在下一篇文章中讲解）为例，介绍内存分配的策略。

#### 对象优先在Eden区分配

==大多数情况下，对象在新生代的Eden区中分配。**当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。**==

#### 大对象直接进入老年代

所谓的大对象是指，需要大量连续内存空间的Java对象，最典型的大对象就是很长的字符串以及数组。大对象对虚拟机的内存分配来说是一个坏消息（尤其是遇到朝生夕灭的“短命大对象”，写程序时应避免），==**经常出现大对象容易导致内存还有不少空间时就提前触发GC以获取足够的连续空间来安置它们**。==

==虚拟机提供了一个**-XX:PretenureSizeThreshold**参数，令大于这个设置值的对象直接在老年代分配。这样做的目的是**避免在Eden区及两个Survivor区之间发生大量的内存复制**（新生代采用复制算法回收内存）。==

#### 长期存活的对象将进入老年代

既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这点，==虚拟机给每个对象定义了一个**对象年龄（Age）计数器**。**如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设为1。对象在Survivor区中每“熬过”一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就将会被晋升到老年代中。**对象晋升老年代的年龄阈值，可以通过参数**-XX:MaxTenuringThreshold**设置。==

#### 动态对象年龄判定

==为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了**MaxTenuringThreshold**才能晋升老年代，**如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代**，无须等到**MaxTenuringThreshold**中要求的年龄。==

#### 空间分配担保

==**在发生Minor GC之前**，虚拟机会先检查**老年代最大可用的连续空间是否大于新生代所有对象总空间**，如果这个条件成立，那么Minor GC可以确保是安全的。如果不成立，则虚拟机会查看**HandlePromotionFailure**设置值是否允许担保失败。如果允许，那么会**继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小**，如果大于，将尝试着进行一次Minor GC，尽管这次Minor GC是有风险的；如果小于，或者**HandlePromotionFailure**设置不允许冒险，那这时也要改为进行一次**Full GC**。==

前面提到过，新生代使用复制收集算法，但为了内存利用率，只使用其中一个Survivor空间来作为轮换备份，因此**当出现大量对象在Minor GC后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把Survivor无法容纳的对象直接进入老年代。**与生活中的贷款担保类似，老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的剩余空间，一共有多少对象会活下来在实际完成内存回收之前是无法明确知道的，所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进行Full GC来让老年代腾出更多空间。

取平均值进行比较其实仍然是一种动态概率的手段，也就是说，如果某次Minor GC存活后的对象突增，远远高于平均值的话，依然会导致**担保失败（Handle Promotion Failure）**。如果出现了**HandlePromotionFailure**失败，那就只好在失败后重新发起一次Full GC。虽然担保失败时绕的圈子是最大的，但大部分情况下都还是会将**HandlePromotionFailure**开关打开，避免Full GC过于频繁。

# Full GC的触发条件

对于Minor GC，其触发条件非常简单，当Eden区空间满时，就将触发一次Minor GC。而Full GC则相对复杂，因此本节我们主要介绍Full GC的触发条件。

#### ==调用System.gc()==

此方法的调用是建议JVM进行Full GC,虽然只是建议而非一定,但很多情况下它会触发 Full GC,从而增加Full GC的频率,也即增加了间歇性停顿的次数。因此强烈建议能不使用此方法就不要使用，让虚拟机自己去管理它的内存，可通过**-XX:+ DisableExplicitGC**来禁止RMI调用System.gc()。

#### ==老年代空间不足==

老年代空间不足的常见场景为前文所讲的**大对象直接进入老年代**、**长期存活的对象进入老年代**等，当执行Full GC后空间仍然不足，则抛出如下错误： `Java.lang.OutOfMemoryError: Java heap space`为避免以上两种状况引起的Full GC，调优时应尽量做到让对象在Minor GC阶段被回收、让对象在新生代多存活一段时间及不要创建过大的对象及数组。

#### ==空间分配担保失败==

前文介绍过，使用复制算法的Minor GC需要老年代的内存空间作担保，如果出现了**HandlePromotionFailure**担保失败，则会触发Full GC。

#### ==JDK 1.7及以前的永久代空间不足==

在JDK 1.7及以前，HotSpot虚拟机中的方法区是用永久代实现的，永久代中存放的为一些class的信息、常量、静态变量等数据，当系统中要加载的类、反射的类和调用的方法较多时，Permanet Generation可能会被占满，在未配置为采用CMS GC的情况下也会执行Full GC。如果经过Full GC仍然回收不了，那么JVM会抛出如下错误信息： `java.lang.OutOfMemoryError: PermGen space` 为避免PermGen占满造成Full GC现象，可采用的方法为增大PermGen空间或转为使用CMS GC。

在JDK 1.8中用元空间替换了永久代作为方法区的实现，元空间是本地内存，因此减少了一种Full GC触发的可能性。

#### Concurrent Mode Failure

执行CMS GC的过程中同时有对象要放入老年代，而此时老年代空间不足（有时候“空间不足”是CMS GC时当前的浮动垃圾过多导致暂时性的空间不足触发Full GC），便会报`Concurrent Mode Failure`错误，并触发Full GC。



# 深入理解JVM(3)——7种垃圾收集器



**如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。**Java虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、版本的虚拟机所提供的垃圾收集器都可能会有很大差别，并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的收集器。接下来讨论的收集器基于JDK1.7 Update 14 之后的HotSpot虚拟机（在此版本中正式提供了商用的G1收集器，之前G1仍处于实验状态），该虚拟机包含的所有收集器如下图所示：

![img](https://pic.yupoo.com/crowhawk/56a02e55/3b3c42d2.jpg)

上图展示了7种作用于不同分代的收集器，如果两个收集器之间存在连线，就说明它们可以搭配使用。虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器。Hotspot实现了如此多的收集器，正是因为目前并无完美的收集器出现，只是选择对具体应用最适合的收集器。

# 相关概念

#### 并行和并发

- **并行（Parallel）**：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。
- **并发（Concurrent）**：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行。而垃圾收集程序运行在另一个CPU上。

#### 吞吐量（Throughput）

吞吐量就是**CPU用于运行用户代码的时间**与**CPU总消耗时间**的比值，即

**吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间）。**

假设虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。

#### Minor GC 和 Full GC

- **新生代GC（Minor GC）**：指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。具体原理见上一篇文章。
- **老年代GC（Major GC / Full GC）**：指发生在老年代的GC，出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。Major GC的速度一般会比Minor GC慢10倍以上。

# 新生代收集器

#### Serial收集器

==**Serial（串行）**收集器是最基本、发展历史最悠久的收集器，它是采用**复制算法**的**新生代收集器**，曾经（JDK 1.3.1之前）是虚拟机**新生代**收集的唯一选择。它是一个单线程收集器，只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是**它在进行垃圾收集时，必须暂停其他所有的工作线程，直至Serial收集器收集结束为止（“Stop The World”）**。这项工作是由虚拟机在后台自动发起和自动完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说是难以接收的。==

下图展示了Serial 收集器（老年代采用Serial Old收集器）的运行过程：

![img](https://pic.yupoo.com/crowhawk/6b90388c/6c281cf0.png)

为了消除或减少工作线程因内存回收而导致的停顿，HotSpot虚拟机开发团队在JDK 1.3之后的Java发展历程中研发出了各种其他的优秀收集器，这些将在稍后介绍。但是这些收集器的诞生并不意味着Serial收集器已经“老而无用”，实际上到现在为止，它依然==是H**otSpot虚拟机运行在Client模式下的默认的新生代收集器**。它也有着优于其他收集器的地方：**简单而高效（与其他收集器的单线程相比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得更高的单线程收集效率。**==

在用户的桌面应用场景中，分配给虚拟机管理的内存一般不会很大，收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存，桌面应用基本不会再大了），停顿时间完全可以控制在几十毫秒最多一百毫秒以内，只要不频繁发生，这点停顿时间可以接收。所以，Serial收集器对于运行在Client模式下的虚拟机来说是一个很好的选择。

#### ParNew 收集器

==**ParNew**收集器就是Serial收集器的多线程版本，它也是一个**新生代收集器**。除了使用多线程进行垃圾收集外，其余行为包括Serial收集器可用的所有控制参数、收集算法（复制算法）、Stop The World、对象分配规则、回收策略等与Serial收集器完全相同，两者共用了相当多的代码。==

ParNew收集器的工作过程如下图（老年代采用Serial Old收集器）：

![img](https://pic.yupoo.com/crowhawk/605f57b5/75122b84.png)

==ParNew收集器除了使用多线程收集外，其他与Serial收集器相比并无太多创新之处，但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关的重要原因是，**除了Serial收集器外，目前只有它能和CMS收集器（Concurrent Mark Sweep）配合工作**，==CMS收集器是JDK 1.5推出的一个具有划时代意义的收集器，具体内容将在稍后进行介绍。

ParNew 收集器在**单CPU的环境**中绝对不会有比Serial收集器有更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证可以超越。在**多CPU环境**下，随着CPU的数量增加，它对于GC时系统资源的有效利用是很有好处的。它默认开启的收集线程数与CPU的数量相同，在CPU非常多的情况下可使用**-XX:ParallerGCThreads**参数设置。

#### Parallel Scavenge 收集器

==**Parallel Scavenge**收集器也是一个**并行**的**多线程新生代**收集器，它也使用**复制算法**。Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标是**达到一个可控制的吞吐量（Throughput）**。==

**停顿时间越短就越适合需要与用户交互的程序**，良好的响应速度能提升用户体验。而**高吞吐量**则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合**在后台运算而不需要太多交互的任务**。

Parallel Scavenge收集器除了会显而易见地提供可以精确控制吞吐量的参数，还提供了一个参数**-XX:+UseAdaptiveSizePolicy**，这是一个开关参数，打开参数后，就不需要手工指定新生代的大小（-Xmn）、Eden和Survivor区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种方式称为**GC自适应的调节策略（GC Ergonomics）**。自适应调节策略也是Parallel Scavenge收集器与ParNew收集器的一个重要区别。

另外值得注意的一点是，Parallel Scavenge收集器无法与CMS收集器配合使用，所以在JDK 1.6推出Parallel Old之前，如果新生代选择Parallel Scavenge收集器，老年代只有Serial Old收集器能与之配合使用。

# 老年代收集器

#### Serial Old收集器

==Serial Old 是 Serial收集器的老年代版本，它同样是一个**单线程收集器**，使用**“标记-整理”（Mark-Compact）**算法。==

==此收集器的主要意义也是在于给Client模式下的虚拟机使用。如果在Server模式下，它还有两大用途：==

- ==在JDK1.5 以及之前版本（Parallel Old诞生以前）中与Parallel Scavenge收集器搭配使用。==
- ==作为CMS收集器的后备预案，在并发收集发生**Concurrent Mode Failure**时使用。==

它的工作流程与Serial收集器相同，这里再次给出Serial/Serial Old配合使用的工作流程图：

![img](https://pic.yupoo.com/crowhawk/6b90388c/6c281cf0.png)

#### Parallel Old收集器

P==arallel Old收集器是Parallel Scavenge收集器的老年代版本，使用**多线程**和**“标记-整理”**算法。==前面已经提到过，这个收集器是在JDK 1.6中才开始提供的，在此之前，如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old以外别无选择，所以在Parallel Old诞生以后，**“吞吐量优先”收集器**终于有了比较名副其实的应用组合，在**注重吞吐量**以及**CPU资源敏感**的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。Parallel Old收集器的工作流程与Parallel Scavenge相同，这里给出Parallel Scavenge/Parallel Old收集器配合使用的流程图：

![img](https://pic.yupoo.com/crowhawk/9a6b1249/b1800d45.png)

#### CMS收集器

==**CMS（Concurrent Mark Sweep）**收集器是一种以**获取最短回收停顿时间**为目标的收集器，它非常符合那些集中在互联网站或者B/S系统的服务端上的Java应用，这些应用都非常重视服务的响应速度。从名字上（“Mark Sweep”）就可以看出它是基于**“标记-清除”**算法实现的。==

CMS收集器工作的整个流程分为以下4个步骤：

- **初始标记（CMS initial mark）**：仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，需要“Stop The World”。
- **并发标记（CMS concurrent mark）**：进行**GC Roots Tracing**的过程，在整个过程中耗时最长。
- **重新标记（CMS remark）**：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。此阶段也需要“Stop The World”。
- **并发清除（CMS concurrent sweep）**

由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。通过下图可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的时间：

![img](https://pic.yupoo.com/crowhawk/fffcf9a2/f60599b2.png)

**优点**

CMS是一款优秀的收集器，它的主要**优点**在名字上已经体现出来了：**并发收集**、**低停顿**，因此CMS收集器也被称为**并发低停顿收集器（Concurrent Low Pause Collector）**。

**缺点**

- **对CPU资源非常敏感** 其实，面向并发设计的程序都对CPU资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。**CMS默认启动的回收线程数是（CPU数量+3）/4**，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是**当CPU不足4个时（比如2个），CMS对用户程序的影响就可能变得很大**，如果本来CPU负载就比较大，还要分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然降低了50%，其实也让人无法接受。
- **无法处理浮动垃圾（Floating Garbage）** 可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。==**由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生。**这一部分垃圾出现在标记过程之后，CMS无法再当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就被称为**“浮动垃圾”**。==也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。
- **标记-清除算法导致的空间碎片** CMS是一款基于“标记-清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象。

# G1收集器

**G1（Garbage-First）**收集器是当今收集器技术发展最前沿的成果之一，它是一款**面向服务端应用**的垃圾收集器，HotSpot开发团队赋予它的使命是（在比较长期的）未来可以替换掉JDK 1.5中发布的CMS收集器。与其他GC收集器相比，G1具备如下特点：

- **并行与并发** G1 能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短“Stop The World”停顿时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。
- **分代收集** 与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同方式去处理新创建的对象和已存活一段时间、熬过多次GC的旧对象来获取更好的收集效果。
- **空间整合** G1从整体来看是基于**“标记-整理”**算法实现的收集器，从局部（两个Region之间）上来看是基于**“复制”**算法实现的。这意味着G1运行期间不会产生内存空间碎片，收集后能提供规整的可用内存。此特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。
- **可预测的停顿** 这是G1相对CMS的一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了降低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在GC上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。

**横跨整个堆内存**

====在G1之前的其他收集器进行收集的范围都是整个新生代或者老生代，而G1不再是这样。G1在使用时，Java堆的内存布局与其他收集器有很大区别，它**将整个Java堆划分为多个大小相等的独立区域（Region）**，虽然还保留新生代和老年代的概念，但**新生代和老年代不再是物理隔离的了，而都是一部分Region（不需要连续）的集合**。====

**建立可预测的时间模型**

====G1收集器之所以能建立可预测的停顿时间模型，是因为它可以**有计划地避免在整个Java堆中进行全区域的垃圾收集**。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），**在后台维护一个优先列表**，每次根据允许的收集时间，**优先回收价值最大的Region（这也就是Garbage-First名称的来由）**。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。====

**避免全堆扫描——Remembered Set**

G1把Java堆分为多个Region，就是“化整为零”。但是Region不可能是孤立的，一个对象分配在某个Region中，可以与整个Java堆任意的对象发生引用关系。在做可达性分析确定对象是否存活的时候，需要扫描整个Java堆才能保证准确性，这显然是对GC效率的极大伤害。

==为了避免全堆扫描的发生，虚拟机**为G1中每个Region维护了一个与之对应的Remembered Set**。虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个Write Barrier暂时中断写操作，检查Reference引用的对象是否处于不同的Region之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过CardTable**把相关引用信息记录到被引用对象所属的Region的Remembered Set之中**。当进行内存回收时，在GC根节点的枚举范围中加入Remembered Set即可保证不对全堆扫描也不会有遗漏。==

------

如果不计算维护Remembered Set的操作，G1收集器的运作大致可划分为以下几个步骤：

- **初始标记（Initial Marking）** 仅仅只是标记一下GC Roots 能直接关联到的对象，并且修改**TAMS（Nest Top Mark Start）**的值，让下一阶段用户程序并发运行时，能在正确可以的Region中创建对象，此阶段需要**停顿线程**，但耗时很短。
- **并发标记（Concurrent Marking）** 从GC Root 开始对堆中对象进行**可达性分析**，找到存活对象，此阶段耗时较长，但**可与用户程序并发执行**。
- **最终标记（Final Marking）** 为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在**线程的Remembered Set Logs**里面，最终标记阶段需要**把Remembered Set Logs的数据合并到Remembered Set中**，这阶段需要**停顿线程**，但是**可并行执行**。
- **筛选回收（Live Data Counting and Evacuation）** 首先对各个Region中的回收价值和成本进行排序，根据用户所期望的GC 停顿是时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。

通过下图可以比较清楚地看到G1收集器的运作步骤中并发和需要停顿的阶段（Safepoint处）：

![img](https://pic.yupoo.com/crowhawk/53b7a589/0bce1667.png)

# 总结

| 收集器                | 串行、并行or并发 | 新生代/老年代 | 算法               | 目标         | 适用场景                                  |
| --------------------- | ---------------- | ------------- | ------------------ | ------------ | ----------------------------------------- |
| **Serial**            | 串行             | 新生代        | 复制算法           | 响应速度优先 | 单CPU环境下的Client模式                   |
| **Serial Old**        | 串行             | 老年代        | 标记-整理          | 响应速度优先 | 单CPU环境下的Client模式、CMS的后备预案    |
| **ParNew**            | 并行             | 新生代        | 复制算法           | 响应速度优先 | 多CPU环境时在Server模式下与CMS配合        |
| **Parallel Scavenge** | 并行             | 新生代        | 复制算法           | 吞吐量优先   | 在后台运算而不需要太多交互的任务          |
| **Parallel Old**      | 并行             | 老年代        | 标记-整理          | 吞吐量优先   | 在后台运算而不需要太多交互的任务          |
| **CMS**               | 并发             | 老年代        | 标记-清除          | 响应速度优先 | 集中在互联网站或B/S系统服务端上的Java应用 |
| **G1**                | 并发             | both          | 标记-整理+复制算法 | 响应速度优先 | 面向服务端应用，将来替换CMS               |

本文通过详细介绍HotSpot虚拟机的7种垃圾收集器回答了上一篇文章开头提出的三个问题中的第三个——“如何回收”，在下一篇文章中，我们将回答最后一个未被解答的问题——“什么时候回收”。



# 深入理解JVM(4)——如何优化Java GC「译」



# GC优化是必要的吗？

或者更准确地说，GC优化对Java基础服务来说是必要的吗？答案是否定的，事实上GC优化对Java基础服务来说在有些场合是可以省去的，但前提是这些正在运行的Java系统，必须包含以下参数或行为：

- 内存大小已经通过**-Xms**和**-Xmx**参数指定过
- 运行在server模式下（使用**-server**参数）
- 系统中没有残留超时日志之类的错误日志

换句话说，如果你在运行时没有手动设置内存大小并且打印出了过多的超时日志，那你就需要对系统进行GC优化。

不过你需要时刻谨记一句话：**GC tuning is the last task to be done.**

现在来想一想GC优化的最根本原因，垃圾收集器的工作就是清除Java创建的对象，垃圾收集器需要清理的对象数量以及要执行的GC数量均取决于已创建的对象数量。因此，为了使你的系统在GC上表现良好，首先需要减少创建对象的数量。

俗话说“冰冻三尺非一日之寒”，我们在编码时要首先要把下面这些小细节做好，否则一些琐碎的不良代码累积起来将让GC的工作变得繁重而难于管理：

- 使用`StringBuilder`或`StringBuffer`来代替`String`
- 尽量少输出日志

尽管如此，仍然会有我们束手无策的情况。XML和JSON解析过程往往占用了最多的内存，即使我们已经尽可能地少用String、少输出日志，仍然会有大量的临时内存（大约10-100MB）被用来解析XML或JSON文件，但我们又很难弃用XML和JSON。在此，你只需要知道这一过程会占据大量内存即可。

如果在经过几次重复的优化后应用程序的内存用量情况有所改善，那么久可以启动GC优化了。

==笔者总结了GC优化的两个目的：==

1. ==**将进入老年代的对象数量降到最低**==
2. ==**减少Full GC的执行时间**==

# 将进入老年代的对象数量降到最低

==除了可以在JDK 7及更高版本中使用的G1收集器以外，其他分代GC都是由Oracle JVM提供的。关于分代GC，就是对象在Eden区被创建，随后被转移到Survivor区，在此之后剩余的对象会被转入老年代。==也有一些对象由于占用内存过大，在Eden区被创建后会直接被传入老年代。老年代GC相对来说会比新生代GC更耗时，因此，减少进入老年代的对象数量可以显著降低Full GC的频率。你可能会以为减少进入老年代的对象数量意味着把它们留在新生代，事实正好相反，==新生代内存的大小是可以调节的。==

# 降低Full GC的时间

Full GC的执行时间比Minor GC要长很多，因此，如果在Full GC上花费过多的时间（超过1s），将可能出现超时错误。

- ==如果**通过减小老年代内存来减少Full GC时间**，可能会引起`OutOfMemoryError`或者导致Full GC的频率升高。==
- ==另外，如果**通过增加老年代内存来降低Full GC的频率**，Full GC的时间可能因此增加。==

==因此，**你需要把老年代的大小设置成一个“合适”的值**。==

# 影响GC性能的参数

正如我在系列的第一篇文章[《理解Java GC》](http://www.cubrid.org/blog/understanding-java-garbage-collection)末尾提到的，不要幻想着“如果有人用他设置的GC参数获取了不错的性能，我们为什么不复制他的参数设置呢？”，因为对于不用的Web服务，它们创建的对象大小和生命周期都不相同。

举一个简单的例子，如果一个任务的执行条件是A，B，C，D和E，另一个完全相同的任务执行条件只有A和B，那么哪一个任务执行速度更快呢？作为常识来讲，答案很明显是后者。

Java GC参数的设置也是这个道理，设置好几个参数并不会提升GC执行的速度，反而会使它变得更慢。**GC优化的基本原则**是将不同的GC参数应用到两个及以上的服务器上然后比较它们的性能，然后将那些被证明可以提高性能或减少GC执行时间的参数应用于最终的工作服务器上。

下面这张表展示了与内存大小相关且会影响GC性能的GC参数

**表1：GC优化需要考虑的JVM参数**

| **类型**       | **参数**            | **描述**                   |
| -------------- | ------------------- | -------------------------- |
| 堆内存大小     | `-Xms`              | 启动JVM时堆内存的大小      |
|                | `-Xmx`              | 堆内存最大限制             |
| 新生代空间大小 | `-XX:NewRatio`      | 新生代和老年代的内存比     |
|                | `-XX:NewSize`       | 新生代内存大小             |
|                | `-XX:SurvivorRatio` | Eden区和Survivor区的内存比 |

笔者在进行GC优化时最常用的参数是`-Xms`,`-Xmx`和`-XX:NewRatio`。`-Xms`和`-Xmx`参数通常是必须的，所以`NewRatio`的值将对GC性能产生重要的影响。

有些人可能会问**如何设置永久代内存大小**，你可以用`-XX:PermSize`和`-XX:MaxPermSize`参数来进行设置，但是要记住，只有当出现`OutOfMemoryError`错误时你才需要去设置永久代内存。

还有一个会影响GC性能的因素是[垃圾收集器的类型](https://crowhawk.github.io/2017/08/15/jvm_3/),下表展示了关于GC类型的可选参数（基于JDK 6.0）：

**表2：GC类型可选参数**

| **GC类型**             | **参数**                                                     | **备注**                        |
| ---------------------- | ------------------------------------------------------------ | ------------------------------- |
| Serial GC              | -XX:+UseSerialGC                                             |                                 |
| Parallel GC            | -XX:+UseParallelGC</br>-XX:ParallelGCThreads=value           |                                 |
| Parallel Compacting GC | -XX:+UseParallelOldGC                                        |                                 |
| CMS GC                 | -XX:+UseConcMarkSweepGC</br>-XX:+UseParNewGC</br>-XX:+CMSParallelRemarkEnabled</br>-XX:CMSInitiatingOccupancyFraction=value</br>-XX:+UseCMSInitiatingOccupancyOnly |                                 |
| G1                     | -XX:+UnlockExperimentalVMOptions</br>-XX:+UseG1GC            | 在JDK 6中这两个参数必须配合使用 |

除了G1收集器外，可以通过设置上表中每种类型第一行的参数来切换GC类型，最常见的非侵入式GC就是Serial GC，它针对客户端系统进行了特别的优化。

会影响GC性能的参数还有很多，但是上述的参数会带来最显著的效果，请切记，设置太多的参数并不一定会提升GC的性能。

# GC优化的过程

GC优化的过程和大多数常见的提升性能的过程相似，下面是笔者使用的流程：

#### 1.监控GC状态

你需要监控GC从而检查系统中运行的GC的各种状态，具体方法请查看系列的第二篇文章[《如何监控Java GC》](http://www.cubrid.org/blog/how-to-monitor-java-garbage-collection)

#### 2.分析监控结果后决定是否需要优化GC

在检查GC状态后，你需要分析监控结构并决定是否需要进行GC优化。如果分析结果显示运行GC的时间只有0.1-0.3秒，那么就不需要把时间浪费在GC优化上，但如果运行GC的时间达到1-3秒，甚至大于10秒，那么GC优化将是很有必要的。

但是，如果你已经分配了大约10GB内存给Java，并且这些内存无法省下，那么就无法进行GC优化了。在进行GC优化之前，你需要考虑为什么你需要分配这么大的内存空间，如果你分配了1GB或2GB大小的内存并且出现了`OutOfMemoryError`，那你就应该执行**堆转储（heap dump）**来消除导致异常的原因。

> 注意：

> **堆转储（heap dump）**是一个用来检查Java内存中的对象和数据的内存文件。该文件可以通过执行JDK中的`jmap`命令来创建。在创建文件的过程中，所有Java程序都将暂停，因此，不要再系统执行过程中创建该文件。

> 你可以在互联网上搜索heap dump的详细说明。对于韩国读者，可以直接参考我去年发布的书：[《The story of troubleshooting for Java developers and system operators》](http://book.naver.com/bookdb/book_detail.nhn?bid=6654751) (Sangmin Lee, Hanbit Media, 2011, 416 pages)

#### 3.设置GC类型/内存大小

如果你决定要进行GC优化，那么你需要选择一个GC类型并且为它设置内存大小。此时如果你有多个服务器，请如上文提到的那样，在每台机器上设置不同的GC参数并分析它们的区别。

#### 4.分析结果

在设置完GC参数后就可以开始收集数据，请在收集至少24小时后再进行结果分析。如果你足够幸运，你可能会找到系统的最佳GC参数。如若不然，你还需要分析输出日志并检查分配的内存，然后需要通过不断调整GC类型/内存大小来找到系统的最佳参数。

#### 5.如果结果令人满意，将参数应用到所有服务器上并结束GC优化

如果GC优化的结果令人满意，就可以将参数应用到所有服务器上，并停止GC优化。

在下面的章节中，你将会看到上述每一步所做的具体工作。

# 监控GC状态并分析结果

在运行中的Web应用服务器（Web Application Server,WAS）上查看GC状态的最佳方式就是使用`jstat`命令。笔者在[《如何监控Java GC》](http://www.cubrid.org/blog/how-to-monitor-java-garbage-collection)中已经介绍过了`jstat`命令，所以在本篇文章中我将着重关注数据部分。

下面的例子展示了某个还没有执行GC优化的JVM的状态（虽然它并不是运行服务器）。

```
$ jstat -gcutil 21719 1s
S0    S1    E    O    P    YGC    YGCT    FGC    FGCT GCT
48.66 0.00 48.10 49.70 77.45 3428 172.623 3 59.050 231.673
48.66 0.00 48.10 49.70 77.45 3428 172.623 3 59.050 231.673
```

我们先看一下YGC（从应用程序启动到采样时发生 Young GC 的次数）和YGCT（从应用程序启动到采样时 Young GC 所用的时间(秒)），计算YGCT/YGC会得出，平均每次新生代的GC耗时50ms，这是一个很小的数字，通过这个结果可以看出，我们大可不必关注新生代GC对GC性能的影响。

现在来看一下FGC（	从应用程序启动到采样时发生 Full GC 的次数）和FGCT（从应用程序启动到采样时 Full GC 所用的时间(秒)），计算FGCT/FGC会得出，平均每次老年代的GC耗时19.68s。有可能是执行了三次Full GC，每次耗时19.68s，也有可能是有两次只花了1s,另一次花了58s。不管是哪一种情况，GC优化都是很有必要的。

使用`jstat`命令可以很容易地查看GC状态，但是分析GC的最佳方式是加上`-verbosegc`参数来生成日志。在之前的文章中笔者已经解释了如何分析这些日志。**HPJMeter**是笔者最喜欢的用于分析`-verbosegc`生成的日志的工具，它简单易用，使用HPJmeter可以很容易地查看GC执行时间以及GC发生频率。

此外，如果GC执行时间满足下列所有条件，就没有必要进行GC优化了：

- Minor GC执行非常迅速（50ms以内）
- Minor GC没有频繁执行（大约10s执行一次）
- Full GC执行非常迅速（1s以内）
- Full GC没有频繁执行（大约10min执行一次）

括号中的数字并不是绝对的，它们也随着服务的状态而变化。有些服务可能要求一次Full GC在0.9s以内，而有些则会放得更宽一些。因此，对于不同的服务，需要按照不同的标准考虑是否需要执行GC优化。

当检查GC状态时，不能只查看Minor GC和Full GC的时间，还必须要**关注GC执行的次数**。如果新生代空间太小，Minor GC将会非常频繁地执行（有时每秒会执行一次，甚至更多）。此外，传入老年代的对象数目会上升，从而导致Full GC的频率升高。因此，在执行`jstat`命令时，请使用`-gccapacity`参数来查看具体占用了多少空间。

# 设置GC类型/内存大小

#### 设置GC类型

Oracle JVM有5种垃圾收集器，但是在JDK 7以前的版本中，你只能在Parallel GC, Parallel Compacting GC 和CMS GC之中选择，至于具体选择哪个，则没有具体的原则和规则。

既然这样的话，**我们如何来选择GC呢？**最好的方法是把三种都用上，但是有一点必须明确——CMS GC通常比其他并行（Parallel）GC都要快（这是因为CMS GC是并发的GC），如果确实如此，那只选择CMS GC就可以了，不过CMS GC也不总是更快，当出现**concurrent mode failure**时，CMS GC就会比并行GC更慢了。

**Concurrent mode failure**

现在让我们来深入地了解一下**concurrent mode failure**。

并行GC和CMS GC的最大区别是并行GC采用“标记-整理”(Mark-Compact)算法而CMS GC采用“标记-清除”(Mark-Sweep)算法（具体内容可参照译者的文章[《GC算法与内存分配策略》](https://crowhawk.github.io/2017/08/10/jvm_2/)）,compact步骤就是通过移动内存来消除内存碎片，从而消除分配的内存之间的空白区域。

对于并行GC来说，无论何时执行Full GC，都会进行compact工作，这消耗了太多的时间。不过在执行完Full GC后，下次内存分配将会变得更快（因为直接顺序分配相邻的内存）。

相反，CMS GC没有compact的过程，因此CMS GC运行的速度更快。但是也是由于没有整理内存，在进行磁盘清理之前，内存中会有很多零碎的空白区域，这也导致没有足够的空间分配给大对象。例如，在老年代还有300MB可用空间，但是连一个10MB的对象都没有办法被顺序存储在老年代中，在这种情况下，会报出**“concurrent mode failure”**的warning，然后系统执行compact操作。但是CMS GC在这种情况下执行的compact操作耗时要比并行GC高很多，并且这还会导致另一个问题，关于**“concurrent mode failure”**的详细说明，可用参考Oracle工程师撰写的[《Understanding CMS GC Logs》](https://blogs.oracle.com/poonam/understanding-cms-gc-logs)。

综上所述，你需要根据你的系统情况为其选择一个最适合的GC类型。

每个系统都有最适合它的GC类型等着你去寻找，如果你有6台服务器，我建议你每两个服务器设置相同的参数，然后加上`-verbosegc`参数再分析结果。

#### 设置内存大小

下面展示了内存大小、GC运行次数和GC运行时间之间的关系：

**大内存空间**

- 减少了GC的次数
- 提高了GC的运行时间

**小内存空间**

- 增多了GC的次数
- 降低了GC的运行时间

关于如何设置内存的大小，没有一个标准答案，如果服务器资源充足并且Full GC能在1s内完成，把内存设为10GB也是可以的，但是大部分服务器并不处在这种状态中，当内存设为10GB时，Full GC会耗时10-30s,具体的时间自然与对象的大小有关。

既然如此，**我们该如何设置内存大小呢？**通常我推荐设为500MB，这不是说你要通过`-Xms500m`和`-Xmx500m`参数来设置WAS内存。根据GC优化之前的状态，如果Full GC后还剩余300MB的空间，那么把内存设为1GB是一个不错的选择（300MB（默认程序占用）+ 500MB（老年代最小空间）+200MB（空闲内存））。这意味着你需要为老年代设置至少500MB空间，因此如果你有三个运行服务器，可以把它们的内存分别设置为1GB，1.5GB，2GB，然后检查结果。

理论上来说，GC执行速度应该遵循1GB> 1.5GB> 2GB，1GB内存时GC执行速度最快。然而，理论上的1GB内存Full GC消耗1s、2GB内存Full GC消耗2 s在现实里是无法保证的，实际的运行时间还依赖于服务器的性能和对象大小。因此，最好的方法是创建尽可能多的测量数据并监控它们。

在设置内存空间大小时，你还需要设置一个参数：`NewRatio`。`NewRatio`的值是新生代和老年代空间大小的比例。如果`XX:NewRatio=1`，则新生代空间:老年代空间=1:1，如果堆内存为1GB，则新生代:老年代=500MB:500MB。如果`NewRatio`等于2，则新生代:老年代=1:2，因此，`NewRatio`的值设置得越大，则老年代空间越大，新生代空间越小。

你可能会认为把`NewRatio`设为1会是最好的选择，然而事实并非如此，根据笔者的经验，当`NewRatio`设为2或3时，整个GC的状态表现得更好。

**完成GC优化最快地方法是什么？**答案是比较性能测试的结果。为了给每台服务器设置不同的参数并监控它们，最好查看的是一或两天后的数据。当通过性能测试来进行GC优化时，你需要在不同的测试时保证它们有相同的负载和运行环境。然而，即使是专业的性能测试人员，想精确地控制负载也很困难，并且需要大量的时间准备。因此，更加方便容易的方式是直接设置参数来运行，然后等待运行的结果（即使这需要消耗更多的时间）。

# 分析GC优化的结果

在设置了GC参数和`-verbosegc`参数后，可以使用tail命令确保日志被正确地生成。如果参数设置得不正确或日志未生成，那你的时间就被白白浪费了。如果日志收集没有问题的话，在收集一或两天数据后再检查结果。最简单的方法是把日志从服务器移到你的本地PC上，然后用**HPJMeter**分析数据。

在分析结果时，请关注下列几点（这个优先级是笔者根据自己的经验拟定的，我认为选取GC参数时应考虑的最重要的因素是Full GC的运行时间。）：

- 单次Full GC运行时间
- 单次Minor GC运行时间
- Full GC运行间隔
- Minor GC运行间隔
- 整个Full GC的时间
- 整个Minor GC的运行时间
- 整个GC的运行时间
- Full GC的执行次数
- Minor GC的执行次数

找到最佳的GC参数是件非常幸运的，然而在大多数时候，我们并不会如此幸运，在进行GC优化时一定要小心谨慎，因为当你试图一次完成所有的优化工作时，可能会出现`OutOfMemoryError`错误。

# 优化案例

到目前为止，我们一直在从理论上介绍GC优化，现在是时候将这些理论付诸实践了，我们将通过几个例子来更深入地理解GC优化。

#### 示例1

下面这个例子是针对**Service S**的优化，对于最近刚开发出来的Service S，执行Full GC需要消耗过多的时间。

现在看一下执行`jstat -gcutil`的结果

```
S0 S1 E O P YGC YGCT FGC FGCT GCT
12.16 0.00 5.18 63.78 20.32 54 2.047 5 6.946 8.993
```

左边的Perm区的值对于最初的GC优化并不重要，而YGC参数的值更加对于这次优化更为重要。

平均执行一次Minor GC和Full GC消耗的时间如下表所示：

**表3：Service S的Minor GC 和Full GC的平均执行时间**

| **GC类型** | **GC执行次数** | GC执行时间 | 平均值 |
| ---------- | -------------- | ---------- | ------ |
| Minor GC   | 54             | 2.047s     | 37ms   |
| Full GC    | 5              | 6.946s     | 1.389s |

**37ms**对于Minor GC来说还不赖，但1.389s对于Full GC来说意味着当GC发生在数据库Timeout设置为1s的系统中时，可能会频繁出现超时现象。

首先，你需要检查开始GC优化前内存的使用情况。使用`jstat -gccapacity`命令可以检查内存用量情况。在笔者的服务器上查看到的结果如下：

```
NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC PGCMN PGCMX PGC PC YGC FGC
212992.0 212992.0 212992.0 21248.0 21248.0 170496.0 1884160.0 1884160.0 1884160.0 1884160.0 262144.0 262144.0 262144.0 262144.0 54 5
```

其中的关键值如下：

- 新生代内存用量：212,992 KB
- 老年代内存用量：1,884,160 KB

因此，除了永久代以外，被分配的内存空间加起来有2GB，并且新生代：老年代=1：9，为了得到比使用`jstat`更细致的结果，还需加上`-verbosegc`参数获取日志，并把三台服务器按照如下方式设置（除此以外没有使用任何其他参数）：

- NewRatio=2
- NewRatio=3
- NewRatio=4

一天后我得到了系统的GC log，幸运的是，在设置完NewRatio后系统没有发生任何Full GC。

**这是为什么呢？**这是因为大部分对象在创建后很快就被回收了，所有这些对象没有被传入老年代，而是在新生代就被销毁回收了。

在这样的情况下，就没有必要去改变其他的参数值了，只要选择一个最合适的`NewRatio`值即可。那么，**如何确定最佳的NewRatio值呢？**为此，我们分析一下每种`NewRatio`值下Minor GC的平均响应时间。

在每种参数下Minor GC的平均响应时间如下：

- NewRatio=2：45ms
- NewRatio=3：34ms
- NewRatio=4：30ms

我们可以根据GC时间的长短得出NewRatio=4是最佳的参数值（尽管NewRatio=4时新生代空间是最小的）。在设置完GC参数后，服务器没有发生Full GC。

为了说明这个问题，下面是服务执行一段时间后执行`jstat –gcutil`的结果:

```
S0 S1 E O P YGC YGCT FGC FGCT GCT
8.61 0.00 30.67 24.62 22.38 2424 30.219 0 0.000 30.219
```

你可能会认为是服务器接收的请求少才使得GC发生的频率较低，实际上，虽然Full GC没有执行过，但Minor GC被执行了2424次。

#### 示例2

这是一个Service A的例子。我们通过公司内部的应用性能管理系统（APM）发现JVM暂停了相当长的时间（超过8秒），因此我们进行了GC优化。我们努力寻找JVM暂停的原因，后来发现是因为Full GC执行时间过长，因此我们决定进行GC优化。

在GC优化的开始阶段，我们加上了`-verbosegc`参数，结果如下图所示：

![img](https://pic.yupoo.com/crowhawk/ebb4b181/a24f4e9b.png)

**图1：进行GC优化之前STW的时间**

上图是由HPJMeter生成的图片之一。横坐标表示JVM执行的时间，纵坐标表示每次GC的时间。CMS为绿点，表示Full GC的结果，而Parallel Scavenge为蓝点，表示Minor GC的结果。

之前我说过CMS GC是最快的GC，但是上面的结果显示在一些时候CMS耗时达到了15s。**是什么导致了这一结果？**请记住我之前说的：CMS在执行compact（整理）操作时会显著变慢。此外，服务的内存通过`-Xms1g`和`=Xmx4g`设置了，而分配的内存只有4GB。

因此笔者将GC类型从CMS GC改为了Parallel GC，把内存大小设为2GB，并把`NewRatio`设为3。在执行`jstat -gcutil`几小时后的结果如下：

```
S0 S1 E O P YGC YGCT FGC FGCT GCT
0.00 30.48 3.31 26.54 37.01 226 11.131 4 11.758 22.890
```

Full GC的时间缩短了，变成了每次3s，跟15s比有了显著提升。但是3s依然不够快，为此笔者创建了以下6种情况：

- Case 1: `-XX:+UseParallelGC -Xms1536m -Xmx1536m -XX:NewRatio=2`
- Case 2: `-XX:+UseParallelGC -Xms1536m -Xmx1536m -XX:NewRatio=3`
- Case 3: `-XX:+UseParallelGC -Xms1g -Xmx1g -XX:NewRatio=3`
- Case 4: `-XX:+UseParallelOldGC -Xms1536m -Xmx1536m -XX:NewRatio=2`
- Case 5: `-XX:+UseParallelOldGC -Xms1536m -Xmx1536m -XX:NewRatio=3`
- Case 6: `-XX:+UseParallelOldGC -Xms1g -Xmx1g -XX:NewRatio=3`

**上面哪一种情况最快？**结果显示，内存空间越小，运行结果最少。下图展示了性能最好的Case 6的结果图，它的最慢响应时间只有1.7s，并且响应时间的平均值已经被控制到了1s以内。

![img](https://pic.yupoo.com/crowhawk/026cb5ec/dd3bdbb9.png)

**图2：Case 6的持续时间图**

基于上图的结果，按照Case 6调整了GC参数，但这却导致每晚都会发生`OutOfMemoryError`。很难解释发生异常的具体原因，简单地说，应该是批处理程序导致了内存泄漏，我们正在解决相关的问题。

如果只对GC日志做一些短时间的分析就将相关参数部署到所有服务器上来执行GC优化，这将是非常危险的。切记，只有当你同时仔细分析服务的执行情况和GC日志后，才能保证GC优化没有错误地执行。

在上文中，我们通过两个GC优化的例子来说明了GC优化是怎样执行的。正如上文中提到的，例子中设置的GC参数可以设置在相同的服务器之上，但前提是他们具有相同的CPU、操作系统、JDK版本并且运行着相同的服务。此外，不要把我使用的参数照搬到你的应用上，它们可能在你的机器上并不能起到同样良好的效果。

# 总结

笔者没有执行heap dump并分析内存的详细内容，而是通过自己的经验进行GC优化。精确地分析内存可以得到更好的优化效果，不过这种分析一般只适用于内存使用量相对固定的场景。如果服务严重过载并占有了大量的内存，则建议你根据之前的经验进行GC优化。

笔者已经在一些服务上设置了G1 GC参数并进行了性能测试，但还没有应用于正式的生产环境。G1 GC的速度快于任何其他的GC类型，但是你必须要升级到JDK 7。此外，暂时还无法保证它的稳定性，没有人知道运行时是否会出现致命的错误，因此G1 GC暂时还不适合投入应用。

等未来JDK 7真正稳定了（这并不是说它现在不稳定），并且WAS针对JDK 7进行优化后，G1 GC最终能按照预期的那样来工作，等到那一天我们可能就不再需要GC优化了。